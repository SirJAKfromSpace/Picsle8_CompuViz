{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numbers\n",
    "import math\n",
    "\n",
    "import copy\n",
    "\n",
    "from pytorch_datasetloader import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch level Discriminator Used In cartoonGAN\n",
    "#code: https://github.com/znxlwm/pytorch-CartoonGAN/\n",
    "class Dis_patch(nn.Module):\n",
    "    \n",
    "    # initializers\n",
    "    def __init__(self, in_nc, out_nc, nf=32):\n",
    "        super(Dis_patch, self).__init__()\n",
    "        self.input_nc = in_nc\n",
    "        self.output_nc = out_nc\n",
    "        self.nf = nf\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(in_nc, nf, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(nf, nf * 2, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(nf * 2, nf * 4, 3, 1, 1),\n",
    "            nn.InstanceNorm2d(nf * 4),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(nf * 4, nf * 4, 3, 2, 1),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(nf * 4, nf * 8, 3, 1, 1),\n",
    "            nn.InstanceNorm2d(nf * 8),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(nf * 8, nf * 8, 3, 1, 1),\n",
    "            nn.InstanceNorm2d(nf * 8),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(nf * 8, out_nc, 3, 1, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "\n",
    "        output = self.convs(input)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gen_unet(nn.Module):\n",
    "    # initializers\n",
    "    def __init__(self, d=64):\n",
    "        super(gen_unet, self).__init__()\n",
    "        # Unet encoder\n",
    "        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
    "        self.conv2 = nn.Conv2d(d, d * 2, 4, 2, 1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(d * 2)\n",
    "        self.conv3 = nn.Conv2d(d * 2, d * 4, 4, 2, 1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(d * 4)\n",
    "        self.conv4 = nn.Conv2d(d * 4, d * 8, 4, 2, 1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(d * 8)\n",
    "        self.conv5 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n",
    "        self.conv5_bn = nn.BatchNorm2d(d * 8)\n",
    "        self.conv6 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n",
    "        self.conv6_bn = nn.BatchNorm2d(d * 8)\n",
    "        self.conv7 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n",
    "        self.conv7_bn = nn.BatchNorm2d(d * 8)\n",
    "        self.conv8 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n",
    "        self.conv8_bn = nn.BatchNorm2d(d * 8)\n",
    "\n",
    "        # Unet decoder\n",
    "        self.deconv1 = nn.ConvTranspose2d(d * 8, d * 8, 4, 2, 1)\n",
    "        self.deconv1_bn = nn.BatchNorm2d(d * 8)\n",
    "        self.deconv2 = nn.ConvTranspose2d(d * 8 * 2, d * 8, 4, 2, 1)\n",
    "        self.deconv2_bn = nn.BatchNorm2d(d * 8)\n",
    "        self.deconv3 = nn.ConvTranspose2d(d * 8 * 2, d * 8, 4, 2, 1)\n",
    "        self.deconv3_bn = nn.BatchNorm2d(d * 8)\n",
    "        self.deconv4 = nn.ConvTranspose2d(d * 8 * 2, d * 8, 4, 2, 1)\n",
    "        self.deconv4_bn = nn.BatchNorm2d(d * 8)\n",
    "        self.deconv5 = nn.ConvTranspose2d(d * 8 * 2, d * 4, 4, 2, 1)\n",
    "        self.deconv5_bn = nn.BatchNorm2d(d * 4)\n",
    "        self.deconv6 = nn.ConvTranspose2d(d * 4 * 2, d * 2, 4, 2, 1)\n",
    "        self.deconv6_bn = nn.BatchNorm2d(d * 2)\n",
    "        self.deconv7 = nn.ConvTranspose2d(d * 2 * 2, d, 4, 2, 1)\n",
    "        self.deconv7_bn = nn.BatchNorm2d(d)\n",
    "        self.deconv8 = nn.ConvTranspose2d(d * 2, 3, 4, 2, 1)\n",
    "\n",
    "    # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            normal_init(self._modules[m], mean, std)\n",
    "\n",
    "    # forward method\n",
    "    def forward(self, input):\n",
    "        e1 = self.conv1(input)\n",
    "        e2 = self.conv2_bn(self.conv2(F.leaky_relu(e1, 0.2)))\n",
    "        e3 = self.conv3_bn(self.conv3(F.leaky_relu(e2, 0.2)))\n",
    "        e4 = self.conv4_bn(self.conv4(F.leaky_relu(e3, 0.2)))\n",
    "        e5 = self.conv5_bn(self.conv5(F.leaky_relu(e4, 0.2)))\n",
    "        e6 = self.conv6_bn(self.conv6(F.leaky_relu(e5, 0.2)))\n",
    "        e7 = self.conv7_bn(self.conv7(F.leaky_relu(e6, 0.2)))\n",
    "        \n",
    "\n",
    "\n",
    "        d1 = F.dropout(self.deconv1_bn(self.deconv1(F.relu(e7))), 0.5, training=True)\n",
    "        d1 = torch.cat([d1, e6], 1)\n",
    "        \n",
    "        d2 = F.dropout(self.deconv2_bn(self.deconv2(F.relu(d1))), 0.5, training=True)\n",
    "        d2 = torch.cat([d2, e5], 1)\n",
    "        \n",
    "        d3 = self.deconv3_bn(self.deconv3(F.relu(d2)))\n",
    "        # d4 = F.dropout(self.deconv4_bn(self.deconv4(F.relu(d3))), 0.5)\n",
    "        \n",
    "        d4 = torch.cat([d3, e4], 1)\n",
    "        d5 = self.deconv5_bn(self.deconv5(F.relu(d4)))\n",
    "        d5 = torch.cat([d5, e3], 1)\n",
    "        d6 = self.deconv6_bn(self.deconv6(F.relu(d5)))\n",
    "        d6 = torch.cat([d6, e2], 1)\n",
    "        d7 = self.deconv7_bn(self.deconv7(F.relu(d6)))\n",
    "        d7 = torch.cat([d7, e1], 1)\n",
    "        d8 = self.deconv8(F.relu(d7))\n",
    "        o = F.tanh(d8)\n",
    "\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling for downsampling was avoided in favor of strided convolutions\n",
    "#based on following paper: https://arxiv.org/pdf/1606.03498.pdf\n",
    "class Gen(nn.Module):\n",
    "    \n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.encode = nn.Sequential(\n",
    "            \n",
    "            #encoding 1\n",
    "            nn.Conv2d(in_channels=3,out_channels=15, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(15),\n",
    "            \n",
    "            #encoding 2\n",
    "            nn.Conv2d(in_channels=15,out_channels=50, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(50),\n",
    "            \n",
    "            #encoding 3\n",
    "            nn.Conv2d(in_channels=50,out_channels=200, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(200)\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.decode = nn.Sequential(\n",
    "            \n",
    "            #decoding 1\n",
    "            nn.ConvTranspose2d(in_channels=200,out_channels=50, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(50),\n",
    "            \n",
    "            #decoding 2\n",
    "            nn.ConvTranspose2d(in_channels=50,out_channels=15, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(15),\n",
    "            \n",
    "            #decoding 3\n",
    "            nn.ConvTranspose2d(in_channels=15,out_channels=3, kernel_size=4, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "\n",
    "        out = self.encode(x)\n",
    "        out = self.decode(out)\n",
    "  \n",
    "        return(out)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet_block(nn.Module):\n",
    "    def __init__(self, channel, kernel, stride, padding):\n",
    "        super(resnet_block, self).__init__()\n",
    "        self.channel = channel\n",
    "        self.kernel = kernel\n",
    "        self.strdie = stride\n",
    "        self.padding = padding\n",
    "        self.conv1 = nn.Conv2d(channel, channel, kernel, stride, padding)\n",
    "        self.conv1_norm = nn.InstanceNorm2d(channel)\n",
    "        self.conv2 = nn.Conv2d(channel, channel, kernel, stride, padding)\n",
    "        self.conv2_norm = nn.InstanceNorm2d(channel)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = F.relu(self.conv1_norm(self.conv1(input)), True)\n",
    "        x = self.conv2_norm(self.conv2(x))\n",
    "\n",
    "        return input + x #Elementwise Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pooling for rescaling was avoided in favor of strided convolutions\n",
    "#based on following paper: https://arxiv.org/pdf/1606.03498.pdf\n",
    "class Custom_Gen_Res(nn.Module):\n",
    "    \n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        self.resnet_blocks = []\n",
    "\n",
    "        self.encode = nn.Sequential(\n",
    "            \n",
    "            #encoding 1\n",
    "            nn.Conv2d(in_channels=3,out_channels=15, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(15),\n",
    "            \n",
    "            #encoding 2\n",
    "            nn.Conv2d(in_channels=15,out_channels=50, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(50),\n",
    "            \n",
    "            #encoding 3\n",
    "            nn.Conv2d(in_channels=50,out_channels=200, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(200)\n",
    "            \n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "        for i in range(4):\n",
    "            self.resnet_blocks.append(resnet_block(200, 3, 1, 1))\n",
    "        \n",
    "        self.resnet_blocks = nn.Sequential(*self.resnet_blocks)\n",
    "        \n",
    "        self.decode = nn.Sequential(\n",
    "            \n",
    "            #decoding 1\n",
    "            nn.ConvTranspose2d(in_channels=200,out_channels=50, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(50),\n",
    "            \n",
    "            #decoding 2\n",
    "            nn.ConvTranspose2d(in_channels=50,out_channels=15, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(15),\n",
    "            \n",
    "            #decoding 3\n",
    "            nn.ConvTranspose2d(in_channels=15,out_channels=3, kernel_size=4, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "\n",
    "        out = self.encode(x)\n",
    "        out = self.resnet_blocks(out)\n",
    "        out = self.decode(out)\n",
    "  \n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Smoother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianSmoothing(nn.Module):\n",
    "    \"\"\"\n",
    "   Apply gaussian smoothing on a\n",
    "   1d, 2d or 3d tensor. Filtering is performed seperately for each channel\n",
    "   in the input using a depthwise convolution.\n",
    "   Arguments:\n",
    "       channels (int, sequence): Number of channels of the input tensors. Output will\n",
    "           have this number of channels as well.\n",
    "       kernel_size (int, sequence): Size of the gaussian kernel.\n",
    "       sigma (float, sequence): Standard deviation of the gaussian kernel.\n",
    "       dim (int, optional): The number of dimensions of the data.\n",
    "           Default value is 2 (spatial).\n",
    "   \"\"\"\n",
    "    def __init__(self, channels, kernel_size, sigma, gcount=1):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        dim = 2\n",
    "        \n",
    "        super(GaussianSmoothing, self).__init__()\n",
    "        if isinstance(kernel_size, numbers.Number):\n",
    "            kernel_size = [kernel_size] * dim\n",
    "        if isinstance(sigma, numbers.Number):\n",
    "            sigma = [sigma] * dim\n",
    " \n",
    "        # The gaussian kernel is the product of the\n",
    "        # gaussian function of each dimension.\n",
    "        kernel = 1\n",
    "        meshgrids = torch.meshgrid(\n",
    "            [\n",
    "                torch.arange(size, dtype=torch.float32)\n",
    "                for size in kernel_size\n",
    "            ]\n",
    "        )\n",
    "        for size, std, mgrid in zip(kernel_size, sigma, meshgrids):\n",
    "            mean = (size - 1) / 2\n",
    "            kernel *= 1 / (std * math.sqrt(2 * math.pi)) * \\\n",
    "                      torch.exp(-((mgrid - mean) / (2 * std)) ** 2)\n",
    " \n",
    "        # Make sure sum of values in gaussian kernel equals 1.\n",
    "        kernel = kernel / torch.sum(kernel)\n",
    " \n",
    "        # Reshape to depthwise convolutional weight\n",
    "        kernel = kernel.view(1, 1, *kernel.size())\n",
    "        kernel = kernel.repeat(channels, *[1] * (kernel.dim() - 1))\n",
    "       \n",
    "        self.gaussCount = gcount\n",
    "#         self.register_buffer('weight', kernel)\n",
    "        self.groups = channels\n",
    "        self.kernel = kernel\n",
    "        self.channels = channels\n",
    " \n",
    "        self.conv = nn.Conv2d(in_channels=channels,out_channels=channels,groups=channels, kernel_size=kernel_size, stride=1, padding=1)\n",
    "\n",
    "\n",
    "            \n",
    "        # weight_init\n",
    "    def weight_init(self, mean, std):\n",
    "        for m in self._modules:\n",
    "            \n",
    "            m.weight.data = self.kernel\n",
    "            \n",
    "            for param in m.parameters():\n",
    "                param.requires_grad = False       \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "       Apply gaussian filter to input.\n",
    "       Arguments:\n",
    "           input (torch.Tensor): Input to apply gaussian filter on.\n",
    "           gaussCount (int): number of times filters are added\n",
    "       Returns:\n",
    "           filtered (torch.Tensor): Filtered output.\n",
    "       \"\"\"\n",
    "       \n",
    "        out = input\n",
    "       \n",
    "        for i in range(self.gaussCount+1):\n",
    "            out = self.conv(out)\n",
    "               \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19 Feature-map Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG19(nn.Module):\n",
    "    def __init__(self, init_weights=None, feature_mode=False, batch_norm=False, num_classes=1000):\n",
    "        super(VGG19, self).__init__()\n",
    "        self.cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "        self.init_weights = init_weights\n",
    "        self.feature_mode = feature_mode\n",
    "        self.batch_norm = batch_norm\n",
    "        self.num_clases = num_classes\n",
    "        self.features = self.make_layers(self.cfg, batch_norm)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "        if not init_weights == None:\n",
    "            self.load_state_dict(torch.load(init_weights))\n",
    "\n",
    "    def make_layers(self, cfg, batch_norm=False):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for v in cfg:\n",
    "            if v == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "                if batch_norm:\n",
    "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "                else:\n",
    "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "                in_channels = v\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.feature_mode:\n",
    "            module_list = list(self.features.modules())\n",
    "            for l in module_list[1:27]:                 # conv4_4\n",
    "                x = l(x)\n",
    "        if not self.feature_mode:\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Generetor and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#using cuda if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# D = Dis()\n",
    "D = Dis_patch(3,1)\n",
    "D = D.to(device)\n",
    "\n",
    "G = Custom_Gen_Res()\n",
    "#G = Gen()\n",
    "G = G.to(device)\n",
    "\n",
    "gausSmoother = GaussianSmoothing(channels=3, kernel_size=3, sigma=1.276, gcount= 40)\n",
    "gausSmoother = gausSmoother.to(device)\n",
    "\n",
    "\n",
    "VGG = VGG19('Pretrained Models/vgg19-dcbb9e9d.pth',feature_mode=True)\n",
    "VGG = VGG.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss().to(device)\n",
    "L1_loss = nn.L1Loss().to(device)\n",
    "\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction Workload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Prexisting Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "#G = Gen_res(3,3)\n",
    "#G.load_state_dict(torch.load('GAN_OUTs/Reconstructing_generator_gen.pkl'))\n",
    "\n",
    "G = Gen()\n",
    "G.load_state_dict(torch.load('GAN_OUTs/custom_DCGAN_recon_init_gen.pkl'))\n",
    "G = G.to(device)\n",
    "\n",
    "\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
    "\n",
    "\n",
    "# path = 'RealFaces_400'\n",
    "# trainloader_nonpixel, validloader_nonpixel = get_loaders(path,batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 images from the dataset\n"
     ]
    }
   ],
   "source": [
    "path = 'RealFaces_350'\n",
    "batch_size_Realpix = 60\n",
    "trainloader_nonpixel, validloader_nonpixel = get_loaders(path,split_perc=1.0,batch_size=batch_size_Realpix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Train Reconstruction Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No [10/2000] Generator Loss: 2.0523\n",
      "Epoch No [20/2000] Generator Loss: 1.9733\n",
      "Epoch No [30/2000] Generator Loss: 1.9891\n",
      "Epoch No [40/2000] Generator Loss: 2.0401\n",
      "Epoch No [50/2000] Generator Loss: 1.9910\n",
      "Epoch No [60/2000] Generator Loss: 1.9713\n",
      "Epoch No [70/2000] Generator Loss: 2.0216\n",
      "Epoch No [80/2000] Generator Loss: 2.0246\n",
      "Epoch No [90/2000] Generator Loss: 1.9702\n",
      "Epoch No [100/2000] Generator Loss: 2.0092\n",
      "Epoch No [110/2000] Generator Loss: 1.9392\n",
      "Epoch No [120/2000] Generator Loss: 2.0156\n",
      "Epoch No [130/2000] Generator Loss: 1.9802\n",
      "Epoch No [140/2000] Generator Loss: 1.9790\n",
      "Epoch No [150/2000] Generator Loss: 1.9639\n",
      "Epoch No [160/2000] Generator Loss: 1.9923\n",
      "Epoch No [170/2000] Generator Loss: 1.9625\n",
      "Epoch No [180/2000] Generator Loss: 2.0307\n",
      "Epoch No [190/2000] Generator Loss: 1.9777\n",
      "Epoch No [200/2000] Generator Loss: 1.9901\n",
      "Epoch No [210/2000] Generator Loss: 1.9965\n",
      "Epoch No [220/2000] Generator Loss: 1.9827\n",
      "Epoch No [230/2000] Generator Loss: 1.9651\n",
      "Epoch No [240/2000] Generator Loss: 1.9797\n",
      "Epoch No [250/2000] Generator Loss: 1.9995\n",
      "Epoch No [260/2000] Generator Loss: 1.9491\n",
      "Epoch No [270/2000] Generator Loss: 1.9532\n",
      "Epoch No [280/2000] Generator Loss: 1.9465\n",
      "Epoch No [290/2000] Generator Loss: 2.0033\n",
      "Epoch No [300/2000] Generator Loss: 1.9968\n",
      "Epoch No [310/2000] Generator Loss: 2.0071\n",
      "Epoch No [320/2000] Generator Loss: 1.9649\n",
      "Epoch No [330/2000] Generator Loss: 1.9570\n",
      "Epoch No [340/2000] Generator Loss: 1.9906\n",
      "Epoch No [350/2000] Generator Loss: 1.9821\n",
      "Epoch No [360/2000] Generator Loss: 1.9691\n",
      "Epoch No [370/2000] Generator Loss: 1.9710\n",
      "Epoch No [380/2000] Generator Loss: 1.9584\n",
      "Epoch No [390/2000] Generator Loss: 1.9048\n",
      "Epoch No [400/2000] Generator Loss: 1.9647\n",
      "Epoch No [410/2000] Generator Loss: 2.0314\n",
      "Epoch No [420/2000] Generator Loss: 1.9674\n",
      "Epoch No [430/2000] Generator Loss: 1.9642\n",
      "Epoch No [440/2000] Generator Loss: 1.9551\n",
      "Epoch No [450/2000] Generator Loss: 2.0045\n",
      "Epoch No [460/2000] Generator Loss: 1.9577\n",
      "Epoch No [470/2000] Generator Loss: 1.9292\n",
      "Epoch No [480/2000] Generator Loss: 1.9274\n",
      "Epoch No [490/2000] Generator Loss: 1.8960\n",
      "Epoch No [500/2000] Generator Loss: 1.9172\n",
      "Epoch No [510/2000] Generator Loss: 1.9729\n",
      "Epoch No [520/2000] Generator Loss: 1.8871\n",
      "Epoch No [530/2000] Generator Loss: 1.9636\n",
      "Epoch No [540/2000] Generator Loss: 1.9056\n",
      "Epoch No [550/2000] Generator Loss: 1.9016\n",
      "Epoch No [560/2000] Generator Loss: 1.9456\n",
      "Epoch No [570/2000] Generator Loss: 1.9417\n",
      "Epoch No [580/2000] Generator Loss: 1.9551\n",
      "Epoch No [590/2000] Generator Loss: 2.0009\n",
      "Epoch No [600/2000] Generator Loss: 1.9665\n",
      "Epoch No [610/2000] Generator Loss: 2.0245\n",
      "Epoch No [620/2000] Generator Loss: 1.8946\n",
      "Epoch No [630/2000] Generator Loss: 1.9431\n",
      "Epoch No [640/2000] Generator Loss: 1.9259\n",
      "Epoch No [650/2000] Generator Loss: 1.8820\n",
      "Epoch No [660/2000] Generator Loss: 1.9377\n",
      "Epoch No [670/2000] Generator Loss: 1.8960\n",
      "Epoch No [680/2000] Generator Loss: 1.9075\n",
      "Epoch No [690/2000] Generator Loss: 1.9243\n",
      "Epoch No [700/2000] Generator Loss: 1.8992\n",
      "Epoch No [710/2000] Generator Loss: 1.8899\n",
      "Epoch No [720/2000] Generator Loss: 1.9181\n",
      "Epoch No [730/2000] Generator Loss: 1.9016\n",
      "Epoch No [740/2000] Generator Loss: 1.9323\n",
      "Epoch No [750/2000] Generator Loss: 1.9513\n",
      "Epoch No [760/2000] Generator Loss: 1.8875\n",
      "Epoch No [770/2000] Generator Loss: 1.9868\n",
      "Epoch No [780/2000] Generator Loss: 1.9407\n",
      "Epoch No [790/2000] Generator Loss: 1.8991\n",
      "Epoch No [800/2000] Generator Loss: 1.8854\n",
      "Epoch No [810/2000] Generator Loss: 1.8727\n",
      "Epoch No [820/2000] Generator Loss: 1.8964\n",
      "Epoch No [830/2000] Generator Loss: 1.8634\n",
      "Epoch No [840/2000] Generator Loss: 1.8745\n",
      "Epoch No [850/2000] Generator Loss: 1.9715\n",
      "Epoch No [860/2000] Generator Loss: 1.8867\n",
      "Epoch No [870/2000] Generator Loss: 1.9280\n",
      "Epoch No [880/2000] Generator Loss: 1.8293\n",
      "Epoch No [890/2000] Generator Loss: 1.9266\n",
      "Epoch No [900/2000] Generator Loss: 1.8732\n",
      "Epoch No [910/2000] Generator Loss: 1.8733\n",
      "Epoch No [920/2000] Generator Loss: 1.9160\n",
      "Epoch No [930/2000] Generator Loss: 1.8840\n",
      "Epoch No [940/2000] Generator Loss: 1.9045\n",
      "Epoch No [950/2000] Generator Loss: 1.8966\n",
      "Epoch No [960/2000] Generator Loss: 1.9306\n",
      "Epoch No [970/2000] Generator Loss: 1.9194\n",
      "Epoch No [980/2000] Generator Loss: 1.8531\n",
      "Epoch No [990/2000] Generator Loss: 1.8411\n",
      "Epoch No [1000/2000] Generator Loss: 1.9218\n",
      "Epoch No [1010/2000] Generator Loss: 1.8694\n",
      "Epoch No [1020/2000] Generator Loss: 1.8771\n",
      "Epoch No [1030/2000] Generator Loss: 1.8434\n",
      "Epoch No [1040/2000] Generator Loss: 1.8953\n",
      "Epoch No [1050/2000] Generator Loss: 1.8450\n",
      "Epoch No [1060/2000] Generator Loss: 1.8781\n",
      "Epoch No [1070/2000] Generator Loss: 1.8700\n",
      "Epoch No [1080/2000] Generator Loss: 1.8638\n",
      "Epoch No [1090/2000] Generator Loss: 1.8608\n",
      "Epoch No [1100/2000] Generator Loss: 1.8336\n",
      "Epoch No [1110/2000] Generator Loss: 1.8849\n",
      "Epoch No [1120/2000] Generator Loss: 1.8222\n",
      "Epoch No [1130/2000] Generator Loss: 1.8435\n",
      "Epoch No [1140/2000] Generator Loss: 1.8393\n",
      "Epoch No [1150/2000] Generator Loss: 1.8462\n",
      "Epoch No [1160/2000] Generator Loss: 1.8902\n",
      "Epoch No [1170/2000] Generator Loss: 1.8844\n",
      "Epoch No [1180/2000] Generator Loss: 1.8370\n",
      "Epoch No [1190/2000] Generator Loss: 1.8351\n",
      "Epoch No [1200/2000] Generator Loss: 1.8411\n",
      "Epoch No [1210/2000] Generator Loss: 1.8623\n",
      "Epoch No [1220/2000] Generator Loss: 1.9017\n",
      "Epoch No [1230/2000] Generator Loss: 1.9790\n",
      "Epoch No [1240/2000] Generator Loss: 1.8630\n",
      "Epoch No [1250/2000] Generator Loss: 1.8070\n",
      "Epoch No [1260/2000] Generator Loss: 1.8371\n",
      "Epoch No [1270/2000] Generator Loss: 1.8093\n",
      "Epoch No [1280/2000] Generator Loss: 1.8349\n",
      "Epoch No [1290/2000] Generator Loss: 1.8474\n",
      "Epoch No [1300/2000] Generator Loss: 1.8866\n",
      "Epoch No [1310/2000] Generator Loss: 1.8627\n",
      "Epoch No [1320/2000] Generator Loss: 1.8154\n",
      "Epoch No [1330/2000] Generator Loss: 1.8275\n",
      "Epoch No [1340/2000] Generator Loss: 1.8555\n",
      "Epoch No [1350/2000] Generator Loss: 1.8074\n",
      "Epoch No [1360/2000] Generator Loss: 1.8595\n",
      "Epoch No [1370/2000] Generator Loss: 1.7866\n",
      "Epoch No [1380/2000] Generator Loss: 1.8854\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-005a25acf454>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0minputImages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_lbls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainiter_nonpixel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0minputImages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputImages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mfake_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputImages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "recon_loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    trainiter_nonpixel = iter(trainloader_nonpixel)\n",
    "    #trainloader_pixel = iter(trainloader_pixel)\n",
    "    \n",
    "    for i in range(5):\n",
    "        \n",
    "        inputImages, input_lbls = trainiter_nonpixel.next()\n",
    "        inputImages = inputImages.to(device)\n",
    "\n",
    "        fake_images = G(inputImages)\n",
    "        \n",
    "        inputImages_fmap = VGG((inputImages + 1) / 2)\n",
    "        G_fmap = VGG((fake_images + 1) / 2)\n",
    "        \n",
    "        Recon_loss = 10 * L1_loss(G_fmap, inputImages_fmap.detach())\n",
    "        \n",
    "        g_optimizer.zero_grad()\n",
    "        Recon_loss.backward()\n",
    "        g_optimizer.step()\n",
    "      \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch No [{}/{}] Generator Loss: {:.4f}'.format(epoch+1,num_epochs,Recon_loss.item()))\n",
    "        #appending loss every 10 epochs\n",
    "        recon_loss_list.append(Recon_loss.item())\n",
    "    \n",
    "        if (epoch+1) % 100 == 0:\n",
    "        # Save fake images\n",
    "            fake_images = fake_images.view(fake_images.size(0), 3, 128, 128)\n",
    "            save_image(fake_images.data, 'images/GAN_IO/fakes/fake_images-%d.png' %(epoch+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Generator\n",
    "torch.save(G.state_dict(), 'GAN_OUTs/Reconstructing_generator_Custom_resgen.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Reconstruction On Different Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_loaders() got an unexpected keyword argument 'num_workers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-c0b6f378155f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'PixelFaces_400'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mim_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_loaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size_Realpix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtestiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: get_loaders() got an unexpected keyword argument 'num_workers'"
     ]
    }
   ],
   "source": [
    "path = 'PixelFaces_400'\n",
    "im_loader, _ = get_loaders(path,batch_size=batch_size_Realpix,num_workers=0)\n",
    "\n",
    "testiter = iter(im_loader)\n",
    "\n",
    "testImages, _ = testiter.next()\n",
    "testImages = testImages.to(device)\n",
    "\n",
    "\n",
    "output = G(testImages)\n",
    "\n",
    "fake_images = output.view(output.size(0), 3, 128, 128)\n",
    "save_image(fake_images.data, 'images/GAN_IO/sample_outputs/recon_sample.png')\n",
    "\n",
    "testImages = testImages.view(testImages.size(0), 3, 128, 128)\n",
    "save_image(testImages.data, 'images/GAN_IO/sample_outputs/recon_input.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Prexisting Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = Gen_res(3,3)\n",
    "# G.load_state_dict(torch.load('GAN_OUTs/Reconstructing_generator.pkl'))\n",
    "\n",
    "# G = Gen()\n",
    "# G.load_state_dict(torch.load('GAN_OUTs/custom_DCGAN_recon_init_gen.pkl'))\n",
    "\n",
    "G = Custom_Gen_Res()\n",
    "G.load_state_dict(torch.load('GAN_OUTs/Reconstructing_generator_Custom_resgen.pkl'))\n",
    "\n",
    "\n",
    "G = G.to(device)\n",
    "\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets for Training DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 images from the dataset\n",
      "250 images from the dataset\n"
     ]
    }
   ],
   "source": [
    "batch_size_Realpix = 50\n",
    "batch_size_mixed = 50\n",
    "dataset_len =  250\n",
    "\n",
    "path = 'RealFaces_350'\n",
    "trainloader_nonpixel, validloader_nonpixel = get_loaders(path,split_perc=1.0,batch_size=batch_size_Realpix)\n",
    "\n",
    "path = 'HollowKnight_250'\n",
    "trainloader_pixel, validloader_pixel = get_loaders(path,split_perc=1.0,batch_size=batch_size_mixed)\n",
    "\n",
    "\n",
    "trainiter_nonpixel = iter(trainloader_nonpixel)\n",
    "trainIter_pixel = iter(trainloader_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No [10/2500] Discriminator Loss: 0.5653, Generator Loss: 1.1923\n",
      "Epoch No [20/2500] Discriminator Loss: 1.1092, Generator Loss: 0.9644\n",
      "Epoch No [30/2500] Discriminator Loss: 1.1519, Generator Loss: 0.8129\n",
      "Epoch No [40/2500] Discriminator Loss: 1.1730, Generator Loss: 0.6393\n",
      "Epoch No [50/2500] Discriminator Loss: 1.2869, Generator Loss: 0.6043\n",
      "Epoch No [60/2500] Discriminator Loss: 1.2076, Generator Loss: 0.6556\n",
      "Epoch No [70/2500] Discriminator Loss: 1.2773, Generator Loss: 0.6474\n",
      "Epoch No [80/2500] Discriminator Loss: 1.2911, Generator Loss: 0.6553\n",
      "Epoch No [90/2500] Discriminator Loss: 1.2368, Generator Loss: 0.6248\n",
      "Epoch No [100/2500] Discriminator Loss: 1.1497, Generator Loss: 0.6439\n",
      "Epoch No [110/2500] Discriminator Loss: 1.2754, Generator Loss: 0.5539\n",
      "Epoch No [120/2500] Discriminator Loss: 1.4861, Generator Loss: 0.6618\n",
      "Epoch No [130/2500] Discriminator Loss: 1.2274, Generator Loss: 0.5740\n",
      "Epoch No [140/2500] Discriminator Loss: 1.3376, Generator Loss: 0.5206\n",
      "Epoch No [150/2500] Discriminator Loss: 1.5770, Generator Loss: 0.6994\n",
      "Epoch No [160/2500] Discriminator Loss: 1.3146, Generator Loss: 0.5427\n",
      "Epoch No [170/2500] Discriminator Loss: 1.3882, Generator Loss: 0.5297\n",
      "Epoch No [180/2500] Discriminator Loss: 1.2750, Generator Loss: 0.5493\n",
      "Epoch No [190/2500] Discriminator Loss: 1.2820, Generator Loss: 0.5426\n",
      "Epoch No [200/2500] Discriminator Loss: 1.1131, Generator Loss: 0.5662\n",
      "Epoch No [210/2500] Discriminator Loss: 1.1708, Generator Loss: 0.5868\n",
      "Epoch No [220/2500] Discriminator Loss: 1.2727, Generator Loss: 0.5322\n",
      "Epoch No [230/2500] Discriminator Loss: 1.4411, Generator Loss: 0.5154\n",
      "Epoch No [240/2500] Discriminator Loss: 1.3657, Generator Loss: 0.4985\n",
      "Epoch No [250/2500] Discriminator Loss: 1.3790, Generator Loss: 0.5008\n",
      "Epoch No [260/2500] Discriminator Loss: 1.3602, Generator Loss: 0.4993\n",
      "Epoch No [270/2500] Discriminator Loss: 1.3876, Generator Loss: 0.4884\n",
      "Epoch No [280/2500] Discriminator Loss: 1.4582, Generator Loss: 0.5152\n",
      "Epoch No [290/2500] Discriminator Loss: 1.3604, Generator Loss: 0.5071\n",
      "Epoch No [300/2500] Discriminator Loss: 1.3786, Generator Loss: 0.5166\n",
      "Epoch No [310/2500] Discriminator Loss: 1.3998, Generator Loss: 0.5078\n",
      "Epoch No [320/2500] Discriminator Loss: 1.3654, Generator Loss: 0.4980\n",
      "Epoch No [330/2500] Discriminator Loss: 1.3987, Generator Loss: 0.4884\n",
      "Epoch No [340/2500] Discriminator Loss: 1.3432, Generator Loss: 0.5004\n",
      "Epoch No [350/2500] Discriminator Loss: 1.3622, Generator Loss: 0.4829\n",
      "Epoch No [360/2500] Discriminator Loss: 1.3643, Generator Loss: 0.4841\n",
      "Epoch No [370/2500] Discriminator Loss: 1.3811, Generator Loss: 0.4809\n",
      "Epoch No [380/2500] Discriminator Loss: 1.3681, Generator Loss: 0.4989\n",
      "Epoch No [390/2500] Discriminator Loss: 1.3736, Generator Loss: 0.4885\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5d1797de7f50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mblurred_fakeimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgausSmoother\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfake_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mfake_classification\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblurred_fakeimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mfake_lbls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_lbls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimsize\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mimsize\u001b[0m \u001b[1;33m//\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\monogatari\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-71c8270f59a5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\monogatari\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\monogatari\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\monogatari\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\monogatari\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 320\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Patch Version with color loss\n",
    "\n",
    "# Train the model\n",
    "total_step = len(trainloader_pixel)\n",
    "d_loss_list = []\n",
    "g_loss_list = []\n",
    "acc_list = []\n",
    "num_epochs = 2500\n",
    "sample_imflag = 0\n",
    "imsize = 128\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    trainiter_nonpixel = iter(trainloader_nonpixel)\n",
    "    trainIter_pixel = iter(trainloader_pixel)\n",
    "    \n",
    "    for i in range(5):\n",
    "        \n",
    "        images, lbls = trainIter_pixel.next()\n",
    "        inputImages, input_lbls = trainiter_nonpixel.next()\n",
    "        \n",
    "        \n",
    "        images = images.to(device)\n",
    "        inputImages = inputImages.to(device)\n",
    "        \n",
    "        labels = torch.ones(len(lbls), 1, imsize // 4 , imsize // 4 ).to(device)\n",
    "        \n",
    "        # Run the forward pass\n",
    "        \n",
    "        #blurring images before feeding to discriminator\n",
    "        blurred_images = gausSmoother(images)\n",
    "        real_classification = D(blurred_images)\n",
    "        \n",
    "\n",
    "        fake_images = G(inputImages).detach()\n",
    "        blurred_fakeimages = gausSmoother(fake_images)\n",
    "        \n",
    "        fake_classification = D(blurred_fakeimages)\n",
    "\n",
    "        fake_lbls = torch.zeros(len(input_lbls), 1, imsize // 4 , imsize // 4 ).to(device)\n",
    "        \n",
    "        d_loss_real = criterion(real_classification, labels)\n",
    "        d_loss_fake = criterion(fake_classification, fake_lbls)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "\n",
    "        # Backprop and perform Adam optimisation for Discriminator\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Discriminator\n",
    "        fake_lbls_duped = torch.ones(len(input_lbls), 1, imsize // 4 , imsize // 4 ).to(device)\n",
    "        fake_lbls_duped = fake_lbls_duped.to(device)\n",
    "   \n",
    "        fake_images = G(inputImages)\n",
    "        blurred_fakeimages = gausSmoother(fake_images)\n",
    "        fake_classification = D(blurred_fakeimages)\n",
    "    \n",
    "        #this loss denotes how well the generator duped/tricked the discriminator\n",
    "        g_loss = criterion(fake_classification, fake_lbls_duped)\n",
    "        \n",
    "        \n",
    "        inputImages_fmap = VGG((inputImages + 1) / 2)\n",
    "        G_fmap = VGG((fake_images + 1) / 2)   \n",
    "        Recon_loss =  L1_loss(G_fmap, inputImages_fmap.detach())\n",
    "        \n",
    "        \n",
    "        g_loss = 0.5*(g_loss + Recon_loss)\n",
    "        \n",
    "        \n",
    "        # Backprop and perform Adam optimisation for generator\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "      \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch No [{}/{}] Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(epoch+1,num_epochs,d_loss.item(),g_loss.item()))\n",
    "        #appending loss every 10 epochs\n",
    "        d_loss_list.append(d_loss.item())\n",
    "        g_loss_list.append(g_loss.item())\n",
    "        \n",
    "        # Save fake images\n",
    "        fake_images = fake_images.view(fake_images.size(0), 3, imsize, imsize)\n",
    "        save_image(fake_images.data, 'images/GAN_IO/fakes/fake_images-%d.png' %(epoch+1))\n",
    "        \n",
    "        \n",
    "        # Save input images\n",
    "        if sample_imflag == 0:\n",
    "            inputImages = inputImages.view(inputImages.size(0), 3, imsize, imsize)\n",
    "            save_image(inputImages.data, 'images/GAN_IO/input_images/inputImages-%d.png' %(epoch+1))\n",
    "            sample_imflag = 1\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No [10/2500] Discriminator Loss: 0.1559, Generator Loss: 10.8409\n",
      "Epoch No [20/2500] Discriminator Loss: 0.0429, Generator Loss: 10.1003\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b746a814260e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0minputImages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputImages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Patch Version \n",
    "\n",
    "# Train the model\n",
    "total_step = len(trainloader_pixel)\n",
    "d_loss_list = []\n",
    "g_loss_list = []\n",
    "acc_list = []\n",
    "num_epochs = 2500\n",
    "sample_imflag = 0\n",
    "imsize = 128\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    trainiter_nonpixel = iter(trainloader_nonpixel)\n",
    "    trainIter_pixel = iter(trainloader_pixel)\n",
    "    \n",
    "    for i in range(5):\n",
    "        \n",
    "        images, lbls = trainIter_pixel.next()\n",
    "        inputImages, input_lbls = trainiter_nonpixel.next()\n",
    "        \n",
    "        \n",
    "        images = images.to(device)\n",
    "        inputImages = inputImages.to(device)\n",
    "        \n",
    "        labels = torch.ones(len(lbls), 1, imsize // 4, imsize // 4).to(device)\n",
    "        \n",
    "        # Run the forward pass\n",
    "\n",
    "        real_classification = D(images)\n",
    "        \n",
    "\n",
    "        fake_images = G(inputImages)\n",
    "        fake_classification = D(fake_images)\n",
    "\n",
    "        fake_lbls = torch.zeros(len(input_lbls), 1, imsize // 4, imsize // 4).to(device)\n",
    "        \n",
    "        d_loss_real = criterion(real_classification, labels)\n",
    "        d_loss_fake = criterion(fake_classification, fake_lbls)\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        \n",
    "\n",
    "        # Backprop and perform Adam optimisation for Discriminator\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        #Discriminator\n",
    "        fake_lbls_duped = torch.ones(len(input_lbls), 1, imsize // 4, imsize // 4).to(device)\n",
    "        fake_lbls_duped = fake_lbls_duped.to(device)\n",
    "   \n",
    "        fake_images = G(inputImages)\n",
    "        fake_classification = D(fake_images)\n",
    "    \n",
    "        #this loss denotes how well the generator duped/tricked the discriminator\n",
    "        g_loss = criterion(fake_classification, fake_lbls_duped)\n",
    "        \n",
    "        \n",
    "        inputImages_fmap = VGG((inputImages + 1) / 2)\n",
    "        G_fmap = VGG((fake_images + 1) / 2)   \n",
    "        Recon_loss =  L1_loss(G_fmap, inputImages_fmap.detach())\n",
    "        \n",
    "        \n",
    "        g_loss = g_loss + 4 * Recon_loss\n",
    "        \n",
    "        \n",
    "        # Backprop and perform Adam optimisation for generator\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "        \n",
    "      \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch No [{}/{}] Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(epoch+1,num_epochs,d_loss.item(),g_loss.item()))\n",
    "        #appending loss every 10 epochs\n",
    "        d_loss_list.append(d_loss.item())\n",
    "        g_loss_list.append(g_loss.item())\n",
    "        \n",
    "        # Save fake images\n",
    "        fake_images = fake_images.view(fake_images.size(0), 3, imsize, imsize)\n",
    "        save_image(fake_images.data, 'images/GAN_IO/fakes/fake_images-%d.png' %(epoch+1))\n",
    "        \n",
    "        \n",
    "        # Save input images\n",
    "        if sample_imflag == 0:\n",
    "            inputImages = inputImages.view(inputImages.size(0), 3, imsize, imsize)\n",
    "            save_image(inputImages.data, 'images/GAN_IO/input_images/inputImages-%d.png' %(epoch+1))\n",
    "            sample_imflag = 1\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCGAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#GANs are saved\n",
    "torch.save(G.state_dict(), 'GAN_OUTs/DCGANPatchGEN_HollowKnight_CustomDCGAN.pkl')\n",
    "torch.save(D.state_dict(), 'GAN_OUTs/DCGANPatchDISC_HollowKnight_CustomDCGAN.pkl')\n",
    "\n",
    "plt.figure(figsize=[12,8])\n",
    "plt.plot(d_loss_list)\n",
    "plt.plot(g_loss_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('x10 Epochs')\n",
    "plt.savefig('images/GAN_LOSS_PLOT/GAN_Loss_CustomCResnet.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 images from the dataset\n",
      "torch.Size([10, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "G = gen_unet()\n",
    "G = G.to(device)\n",
    "G.load_state_dict(torch.load('GAN_OUTs/DCGANPatch_unet.pkl'))\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "path = 'RealFaces_350'\n",
    "trainloader_pixel, _ = get_loaders(path,split_perc=1.0,batch_size=batch_size,num_workers=0)\n",
    "\n",
    "testImages = iter(trainloader_pixel).next()\n",
    "\n",
    "testimg = testImages[0].to(device)\n",
    "print(testimg.shape)\n",
    "\n",
    "output = G(testimg)\n",
    "\n",
    "fake_images = output.view(output.size(0), 3, 128, 128)\n",
    "f = fake_images.detach().cpu().numpy()\n",
    "save_image(fake_images.data, 'images/GAN_IO/CustomDCGAN_unet.png')\n",
    "\n",
    "testImages = testimg.view(testimg.size(0), 3, 128, 128)\n",
    "t = testImages.detach().cpu().numpy()\n",
    "save_image(testimg.data, 'images/GAN_IO/CustomDCGAN_unet_input.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
