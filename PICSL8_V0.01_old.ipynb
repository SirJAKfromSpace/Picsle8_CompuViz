{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import copy\n",
    "\n",
    "from pytorch_datasetloader_old import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Dis(nn.Module):\n",
    "#     def __init__(self):\n",
    "        \n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.model = nn.Sequential(\n",
    "\n",
    "#             #block 1 input = 3*192*192\n",
    "#             nn.Conv2d(in_channels=3,out_channels=15,kernel_size=3),\n",
    "#             # 15*190*190\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(3, stride=2),\n",
    "#             # 15*95*95\n",
    "            \n",
    "            \n",
    "#             #block 2 input = 15*95*95\n",
    "#             nn.Conv2d(in_channels=15,out_channels=50,kernel_size=3),\n",
    "#             # 50*93*93\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(3, stride=2),\n",
    "#             # 50*46*46\n",
    "            \n",
    "            \n",
    "#             #block 3 input = 50*46*46\n",
    "#             nn.Conv2d(in_channels=50,out_channels=200,kernel_size=3),\n",
    "#             # 200*44*44\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(3, stride=2),\n",
    "#             # 200*22*22\n",
    "            \n",
    "#             nn.reshape(out.size(0), -1)\n",
    "            \n",
    "#             #Fully Connected\n",
    "#             nn.Linear(in_features=200*22*22,out_features=120),\n",
    "#             nn.Linear(in_features=120,out_features=60),\n",
    "#             nn.Linear(in_features=60,out_features=1),\n",
    "#             nn.Sigmoid()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#         )\n",
    "    \n",
    "#     def forward(self, input):\n",
    "#         return self.model(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dis(nn.Module):\n",
    "    \n",
    "    #Our batch shape for input x is (3, 32, 32)\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        #block 1 input = 3*128*128 \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=15, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        #block 2 input = 15*64*64\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=15,out_channels=50, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        #block 3 input = 50*32*32\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=50,out_channels=200, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "     \n",
    "        #self.drop_out = nn.Dropout()\n",
    "        self.fc1 = torch.nn.Linear(200*16*16, 120)\n",
    "        self.fc2 = torch.nn.Linear(120, 60)\n",
    "        \n",
    "        self.outlayer = nn.Sequential(\n",
    "            nn.Linear(60, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        #out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.outlayer(out)\n",
    "        \n",
    "        \n",
    "        return(out)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#using cuda if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "D = Dis()\n",
    "D = D.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774 images from the dataset\n"
     ]
    }
   ],
   "source": [
    "path = 'images/'\n",
    "trainloader, validloader = get_loaders(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "#g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining Discriminator Seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [10/17], Loss: 0.6317, Accuracy: 71.88%\n",
      "Epoch [2/100], Step [10/17], Loss: 0.5954, Accuracy: 75.00%\n",
      "Epoch [3/100], Step [10/17], Loss: 0.5495, Accuracy: 81.25%\n",
      "Epoch [4/100], Step [10/17], Loss: 0.3499, Accuracy: 84.38%\n",
      "Epoch [5/100], Step [10/17], Loss: 0.3538, Accuracy: 90.62%\n",
      "Epoch [6/100], Step [10/17], Loss: 0.3213, Accuracy: 93.75%\n",
      "Epoch [7/100], Step [10/17], Loss: 0.2722, Accuracy: 93.75%\n",
      "Epoch [8/100], Step [10/17], Loss: 0.2228, Accuracy: 96.88%\n",
      "Epoch [9/100], Step [10/17], Loss: 0.1651, Accuracy: 100.00%\n",
      "Epoch [10/100], Step [10/17], Loss: 0.1322, Accuracy: 93.75%\n",
      "Epoch [11/100], Step [10/17], Loss: 0.1461, Accuracy: 100.00%\n",
      "Epoch [12/100], Step [10/17], Loss: 0.0653, Accuracy: 100.00%\n",
      "Epoch [13/100], Step [10/17], Loss: 0.0470, Accuracy: 100.00%\n",
      "Epoch [14/100], Step [10/17], Loss: 0.0556, Accuracy: 100.00%\n",
      "Epoch [15/100], Step [10/17], Loss: 0.0388, Accuracy: 100.00%\n",
      "Epoch [16/100], Step [10/17], Loss: 0.0185, Accuracy: 100.00%\n",
      "Epoch [17/100], Step [10/17], Loss: 0.0146, Accuracy: 100.00%\n",
      "Epoch [18/100], Step [10/17], Loss: 0.0302, Accuracy: 100.00%\n",
      "Epoch [19/100], Step [10/17], Loss: 0.0690, Accuracy: 100.00%\n",
      "Epoch [20/100], Step [10/17], Loss: 0.0055, Accuracy: 100.00%\n",
      "Epoch [21/100], Step [10/17], Loss: 0.0083, Accuracy: 100.00%\n",
      "Epoch [22/100], Step [10/17], Loss: 0.2395, Accuracy: 93.75%\n",
      "Epoch [23/100], Step [10/17], Loss: 0.0255, Accuracy: 100.00%\n",
      "Epoch [24/100], Step [10/17], Loss: 0.0354, Accuracy: 100.00%\n",
      "Epoch [25/100], Step [10/17], Loss: 0.0519, Accuracy: 100.00%\n",
      "Epoch [26/100], Step [10/17], Loss: 0.0663, Accuracy: 100.00%\n",
      "Epoch [27/100], Step [10/17], Loss: 0.0137, Accuracy: 100.00%\n",
      "Epoch [28/100], Step [10/17], Loss: 0.0178, Accuracy: 100.00%\n",
      "Epoch [29/100], Step [10/17], Loss: 0.0710, Accuracy: 100.00%\n",
      "Epoch [30/100], Step [10/17], Loss: 0.0265, Accuracy: 96.88%\n",
      "Epoch [31/100], Step [10/17], Loss: 0.0591, Accuracy: 96.88%\n",
      "Epoch [32/100], Step [10/17], Loss: 0.0182, Accuracy: 100.00%\n",
      "Epoch [33/100], Step [10/17], Loss: 0.0923, Accuracy: 90.62%\n",
      "Epoch [34/100], Step [10/17], Loss: 0.1113, Accuracy: 93.75%\n",
      "Epoch [35/100], Step [10/17], Loss: 0.0158, Accuracy: 100.00%\n",
      "Epoch [36/100], Step [10/17], Loss: 0.0064, Accuracy: 100.00%\n",
      "Epoch [37/100], Step [10/17], Loss: 0.0028, Accuracy: 100.00%\n",
      "Epoch [38/100], Step [10/17], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [39/100], Step [10/17], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [40/100], Step [10/17], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [41/100], Step [10/17], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [42/100], Step [10/17], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [43/100], Step [10/17], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [44/100], Step [10/17], Loss: 0.0004, Accuracy: 100.00%\n",
      "Epoch [45/100], Step [10/17], Loss: 0.0004, Accuracy: 100.00%\n",
      "Epoch [46/100], Step [10/17], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [47/100], Step [10/17], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [48/100], Step [10/17], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [49/100], Step [10/17], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [50/100], Step [10/17], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [51/100], Step [10/17], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [52/100], Step [10/17], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [53/100], Step [10/17], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [54/100], Step [10/17], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [55/100], Step [10/17], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [56/100], Step [10/17], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [57/100], Step [10/17], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [58/100], Step [10/17], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [59/100], Step [10/17], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [60/100], Step [10/17], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [61/100], Step [10/17], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [62/100], Step [10/17], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [63/100], Step [10/17], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [64/100], Step [10/17], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [65/100], Step [10/17], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [66/100], Step [10/17], Loss: 0.0001, Accuracy: 100.00%\n",
      "Epoch [67/100], Step [10/17], Loss: 0.0001, Accuracy: 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-44023244d531>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;31m#         , predicted = torch.max(outputs.data, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0macc_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(trainloader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        images = images.to(device) \n",
    "        #labels = labels.to(device)\n",
    "#         labels_compare = labels\n",
    "#         labels_compare = labels.to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.float, device=device)\n",
    "        \n",
    "#         continue\n",
    "        \n",
    "        # Run the forward pass\n",
    "        outputs = D(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "\n",
    "        # Backprop and perform Adam optimisation\n",
    "        d_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        \n",
    "        preds = (outputs >= 0.7)\n",
    "        preds = preds.reshape(-1)\n",
    "        preds = torch.tensor(preds, dtype=torch.float, device=device)\n",
    "        #print(preds)\n",
    "        \n",
    "\n",
    "#         , predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        correct = (preds == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                  .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "                          (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
